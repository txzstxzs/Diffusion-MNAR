{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d97f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0573b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_printoptions(linewidth=150)\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9d0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classify(nn.Module ):\n",
    "    def __init__(self, D):\n",
    "        super(classify, self).__init__()\n",
    "        self.logits_layer = nn.Sequential(\n",
    "                                          nn.Linear(D, D),  # 用同维度的效果好一些\n",
    "#                                           nn.Linear(D, int(D)),\n",
    "                                         nn.ReLU(),\n",
    "#                                          nn.Tanh(),   # 使用这个激活函数效果较好\n",
    "                                         nn.Linear(D, D),\n",
    "#                                          nn.Linear(int(D), D),\n",
    "                                        )\n",
    "                                                                                \n",
    "    \n",
    "    def forward(self, l_out_mixed ):\n",
    "        \n",
    "        logits = self.logits_layer(l_out_mixed)       # 拼接后处理一次 值应该在01之间 概率值 或对数概率值  用于创建努利分布\n",
    "        p_s_given_x = Bernoulli(logits=logits)\n",
    "        \n",
    "        return p_s_given_x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036b8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class classify(nn.Module ):\n",
    "#     def __init__(self, D):\n",
    "#         super(classify, self).__init__()\n",
    "#         self.W              = nn.Parameter(torch.randn(1, 1, D))  # Initialize W parameter\n",
    "#         self.b              = nn.Parameter(torch.randn(1, 1, D))  # Initialize b parameter\n",
    "\n",
    "#     def forward(self, l_out_mixed ):\n",
    "# #         logits      = - self.W * (l_out_mixed - self.b)\n",
    "        \n",
    "#         W_softplus  = F.softplus(self.W)\n",
    "#         logits      = - W_softplus * (l_out_mixed - self.b)\n",
    "        \n",
    "        \n",
    "#         p_s_given_x = Bernoulli(logits=logits)\n",
    "        \n",
    "#         return p_s_given_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fff9211",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/datasets/exchange_rate.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_108056\\1381810221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'exchange_rate'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'./Data/datasets/exchange_rate.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/datasets/exchange_rate.npy'"
     ]
    }
   ],
   "source": [
    "data_name = 'exchange_rate'\n",
    "\n",
    "if data_name == 'exchange_rate':\n",
    "    data = np.load( './Data/datasets/exchange_rate.npy')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa2e6178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33) object\n",
      "(569, 29) object\n",
      "float64\n",
      "569 29\n"
     ]
    }
   ],
   "source": [
    "data = np.array(pd.read_csv('./Cancer_Data.csv', low_memory=False, sep=','))\n",
    "print(data.shape, data.dtype)\n",
    "\n",
    "\n",
    "X_data = data[:, 2:-2]  # Features\n",
    "print(X_data.shape, X_data.dtype )\n",
    "\n",
    "X_data = X_data.astype(float)\n",
    "print( X_data.dtype )\n",
    "\n",
    "N, D = X_data.shape\n",
    "n_latent = D - 1\n",
    "print(N, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bafbbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_missing_superior_to_mean(X):\n",
    "    print(\"Introducing missing data with > mean\")\n",
    "    N, D = X.shape\n",
    "    Xnan = X.copy()\n",
    "\n",
    "    # ---- MNAR in D/2 dimensions\n",
    "    mean = np.mean(Xnan[:, :int(D / 2)], axis=0)\n",
    "    ix_larger_than_mean = Xnan[:, :int(D / 2)] > mean\n",
    "    Xnan[:, :int(D / 2)][ix_larger_than_mean] = np.nan\n",
    "\n",
    "    Xnan = Xnan.astype(np.float32)\n",
    "    Xz = Xnan.copy()\n",
    "    Xz[np.isnan(Xnan.astype(np.float32))] = 0\n",
    "\n",
    "    return Xnan, Xz\n",
    "\n",
    "def introduce_missing_mean_values(X, percentage_to_remove = 30):\n",
    "    print(\"Introduce missing data by removing the values around the mean\")\n",
    "    N, D = X.shape\n",
    "    Xnan = X.copy()\n",
    "\n",
    "    num_elements = int(N * percentage_to_remove / 100)   # number of elements to remove\n",
    "\n",
    "    # ---- MNAR in D/2 dimensions\n",
    "    mean = np.mean(Xnan[:, :int(D / 2)], axis=0)\n",
    "    abs_diff_from_mean = np.abs(Xnan[:, :int(D / 2)] - mean)\n",
    "    indices_to_remove = np.argsort(abs_diff_from_mean, axis = 0)[:num_elements]\n",
    "    # Set those values to NaN\n",
    "    for d in range(indices_to_remove.shape[1]):\n",
    "        Xnan[indices_to_remove[:, d], d] = np.nan\n",
    "    Xnan = Xnan.astype(np.float32)\n",
    "    Xz = Xnan.copy()\n",
    "    Xz[np.isnan(Xnan)] = 0\n",
    "    return Xnan, Xz\n",
    "\n",
    "\n",
    "def introduce_missing_extreme_values(X, percentile_extreme = 25):\n",
    "    print(\"Introducing missing data via removing extreme values\")\n",
    "    N, D = X.shape\n",
    "    Xnan = X.copy()\n",
    "\n",
    "    # ---- MNAR in D/2 dimensions\n",
    "    lower_bound = np.percentile(Xnan[:, :int(D / 2)], percentile_extreme, axis=0)\n",
    "    upper_bound = np.percentile(Xnan[:, :int(D / 2)], 100 - percentile_extreme, axis=0)\n",
    "\n",
    "    ix_lower = Xnan[:, :int(D / 2)] < lower_bound\n",
    "    ix_higher = Xnan[:, :int(D / 2)] > upper_bound\n",
    "    Xnan[:, :int(D / 2)][ix_lower | ix_higher] = np.nan  # 过大过小的去掉 换成nan\n",
    "    Xnan = Xnan.astype(np.float32)\n",
    "    \n",
    "    Xz = Xnan.copy()\n",
    "    Xz[np.isnan(Xnan)] = 0    # 换成0\n",
    "\n",
    "    return Xnan, Xz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def introduce_missing_random(X, percentage_to_remove=30):\n",
    "    \"\"\"\n",
    "    Introduce missing data by randomly removing values from the input matrix\n",
    "\n",
    "    Args:\n",
    "        X: Input numpy array of shape (N, D)\n",
    "        percentage_to_remove: Percentage of values to remove (default: 30)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Array with NaN values, Array with zeros instead of NaN)\n",
    "    \"\"\"\n",
    "    print(\"Introducing random missing data\")\n",
    "    N, D = X.shape\n",
    "    Xnan = X.copy()\n",
    "\n",
    "    # Calculate total number of elements to remove\n",
    "    total_elements = N * D\n",
    "    num_to_remove = int(total_elements * percentage_to_remove / 100)\n",
    "\n",
    "    # Create a flat mask of indices\n",
    "    flat_indices = np.arange(total_elements)\n",
    "\n",
    "    # Randomly select indices to remove\n",
    "    indices_to_remove = np.random.choice(\n",
    "        flat_indices,\n",
    "        size=num_to_remove,\n",
    "        replace=False\n",
    "    )\n",
    "\n",
    "    # Convert flat indices to 2D indices\n",
    "    rows = indices_to_remove // D\n",
    "    cols = indices_to_remove % D\n",
    "\n",
    "    # Set selected values to NaN\n",
    "    Xnan[rows, cols] = np.nan\n",
    "    Xnan = Xnan.astype(np.float32)\n",
    "\n",
    "    # Create version with zeros instead of NaN\n",
    "    Xz = Xnan.copy()\n",
    "    Xz[np.isnan(Xnan)] = 0\n",
    "\n",
    "    # Print some statistics\n",
    "    missing_count = np.isnan(Xnan).sum()\n",
    "    actual_percentage = (missing_count / total_elements) * 100\n",
    "    print(f\"Removed {missing_count} values ({actual_percentage:.2f}%)\")\n",
    "\n",
    "    return Xnan, Xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5c1b474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introducing missing data with > mean\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01]\n",
      "[1.41272917e+01 1.92896485e+01 9.19690334e+01 6.54889104e+02\n",
      " 9.63602812e-02 1.04340984e-01 8.87993158e-02 4.89191459e-02\n",
      " 1.81161863e-01 6.27976098e-02 4.05172056e-01 1.21685343e+00\n",
      " 2.86605923e+00 4.03370791e+01]\n",
      "[      nan 1.038e+01       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan 9.053e-01       nan       nan\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Xnan, Xz = introduce_missing_mean_values(X_data )       # 半维度 relu 0.85\n",
    "Xnan, Xz = introduce_missing_superior_to_mean(X_data )    # 全维度 tanh 0.94   全维度 relu 0.97   半维度 relu 0.97\n",
    "# Xnan, Xz = introduce_missing_extreme_values(X_data )\n",
    "# Xnan, Xz = introduce_missing_random(X_data )\n",
    "print( X_data[0])\n",
    "print( np.mean(X_data[:, :int(D / 2)], axis=0) )\n",
    "print( Xnan[0])\n",
    "# print( Xz[0] )\n",
    "\n",
    "S = np.array(~np.isnan(Xnan), dtype=np.float32)  # 缺失处为0 观测处为1\n",
    "print(S[0] )\n",
    "# print(mean)\n",
    "# print( S.shape )\n",
    "# print( S[0:5] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f96be7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 29])\n",
      "torch.Size([569])\n"
     ]
    }
   ],
   "source": [
    "classi = classify(D=D).to(device)\n",
    "optimizer = optim.Adam( list(classi.parameters()), lr=0.0001)\n",
    "\n",
    "x = torch.tensor(X_data, dtype=torch.float32, device=device) \n",
    "s = torch.tensor(S,      dtype=torch.float32, device=device) \n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "print(torch.sum(s, dim=-1).shape )\n",
    "# torch.mean\n",
    "\n",
    "\n",
    "\n",
    "train_dataset  =  TensorDataset(x, s ) \n",
    "train_loader    = DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "losslist1 = []\n",
    "losslist2 = []\n",
    "for i in range(10000):\n",
    "    \n",
    "    for x_train, s_train in train_loader:\n",
    "        \n",
    "        p_s_given_x = classi(x_train)\n",
    "\n",
    "        # 这个值考虑除以2 因为是两列值相加 但是没有除以2 但测试后发现对结果几乎没有影响\n",
    "        log_p_s_given_x = torch.sum( p_s_given_x.log_prob( s_train ), dim=-1 )  \n",
    "    #     print( log_p_s_given_x.shape)\n",
    "\n",
    "    #     log_sum_w = torch.logsumexp(log_p_s_given_x, dim=0)\n",
    "    #     print( log_sum_w)\n",
    "\n",
    "\n",
    "        '用第一个loss效果好一些 最终应该差不多'\n",
    "        loss = -torch.mean(log_p_s_given_x)\n",
    "\n",
    "    #     loss = -torch.mean(log_sum_w)\n",
    "\n",
    "\n",
    "\n",
    "        losslist1.append(loss.item())\n",
    "        losslist2.append(log_p_s_given_x.mean().item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fa151",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(losslist1, label='loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(losslist2, label='log_p_s_given_x')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b386a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = torch.tensor(X_data, dtype=torch.float32, device=device) \n",
    "test_s = torch.tensor(s, dtype=torch.float32, device=device)\n",
    "print(test_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'输入测试数据 看成生成的缺失掩码 '\n",
    "p_s_given_x = classi(test_data)\n",
    "print(p_s_given_x.sample() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df22ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'真实掩码输入训练的分布 看成能否生成这样的真实掩码 计算对数概率 概率越接近1 对数越接近0'\n",
    "'-----这里计算对数概率时把两列值加起来了 但是没有除以2-----'\n",
    "log_p_s_given_x = torch.sum( p_s_given_x.log_prob(test_s ), dim=-1 )\n",
    "print(log_p_s_given_x.shape)\n",
    "print(log_p_s_given_x.mean().item())\n",
    "\n",
    "'对数概率取指数 得到分类概率'\n",
    "print(torch.exp( torch.tensor( log_p_s_given_x.mean().item()))  )\n",
    "\n",
    "\n",
    "'应该除以2 这样就比较准确 和下面差不多 没有完全一样 应该是因为前面torch.sum()时精确度有损失'\n",
    "log_p_s_given_x = log_p_s_given_x/D\n",
    "print(torch.exp( torch.tensor( log_p_s_given_x.mean().item()))  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d952816",
   "metadata": {},
   "outputs": [],
   "source": [
    "'用这个方法计算分类准确率要高一些 逐个计算概率'\n",
    "p = p_s_given_x.log_prob(test_s).exp()\n",
    "print(p.mean())\n",
    "print(torch.sum(p, dim=-1).mean()/D )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b6562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdeffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ef152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ce76b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
